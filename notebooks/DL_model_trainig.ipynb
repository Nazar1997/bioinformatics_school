{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from matplotlib import pyplot as plt\n",
    "from Sparse_vector.sparse_vector import SparseVector\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Choose visible device\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "# Select model number. From 0 to 4, as much as number of folds\n",
    "MODEL_NUMBER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroms = [f'chr{i}' for i in list(range(1, 20)) + ['X', 'Y']]\n",
    "all_features = sorted([i[:-4] for i in os.listdir('../data/mm9_features/sparse/') if i.endswith('.pkl')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroms = ['chr3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "groups = ['Histone', 'RNA polymerase', 'TFs and others']\n",
    "feature_names = [i for i in all_features if (i.split('_')[0] in groups)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZDNA = load(f'../data/mm9_zdna/sparse/zdna_mm9.pkl')\n",
    "black_list = load(f'../data/mm9_zdna/sparse/blacklist_mm9.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
      "100%|██████████| 870/870 [00:01<00:00, 820.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.38 s, sys: 338 ms, total: 1.72 s\n",
      "Wall time: 2.04 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load all the data\n",
    "DNA = {chrom:load(f'../data/mm9_dna/sparse/{chrom}.pkl') for chrom in tqdm(chroms)}\n",
    "\n",
    "DNA_features = {feture: load(f'../data/mm9_features/sparse/{feture}.pkl')\n",
    "                for feture in tqdm(feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 870/870 [00:00<00:00, 813248.16it/s]\n"
     ]
    }
   ],
   "source": [
    "for feature in tqdm(DNA_features):\n",
    "    if set(DNA_features[feature].keys()) != set(chroms):\n",
    "        for chrom in chroms:\n",
    "            if chrom not in DNA_features[feature]:\n",
    "                DNA_features[feature][chrom] = SparseVector(len(DNA[chrom]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, chroms, features, \n",
    "                 dna_source, features_source, \n",
    "                 labels_source, intervals):\n",
    "        self.chroms = chroms\n",
    "        self.features = features\n",
    "        self.dna_source = dna_source\n",
    "        self.features_source = features_source\n",
    "        self.labels_source = labels_source\n",
    "        self.intervals = intervals\n",
    "        self.le = LabelBinarizer().fit(np.array([[\"A\"], [\"C\"], [\"T\"], [\"G\"]]))\n",
    "        zhunt = \"\"\"CG 0.7 4.0 4.0 4.0\n",
    "GC 4.0 0.7 4.0 4.0\n",
    "CA 1.3 4.6 4.5 4.5\n",
    "AC 4.6 1.3 4.5 4.5\n",
    "TG 1.3 4.6 4.5 4.5\n",
    "GT 4.6 1.3 4.5 4.5\n",
    "TA 2.5 5.9 5.6 5.6\n",
    "AT 5.9 2.5 5.6 5.6\n",
    "CC 2.4 2.4 4.0 4.0\n",
    "GG 2.4 2.4 4.0 4.0\n",
    "CT 3.4 3.4 6.3 6.3\n",
    "TC 3.4 3.4 6.3 6.3\n",
    "GA 3.4 3.4 6.3 6.3\n",
    "AG 3.4 3.4 6.3 6.3\n",
    "AA 3.9 3.9 7.4 7.4\n",
    "TT 3.9 3.9 7.4 7.4\"\"\"\n",
    "        ZHUNT_AS = {line.split(' ')[0]:float(line.split(' ')[1]) \n",
    "              for line in zhunt.split('\\n')}\n",
    "        ZHUNT_SA = {line.split(' ')[0]:float(line.split(' ')[2]) \n",
    "              for line in zhunt.split('\\n')}\n",
    "        ZHUNT_ASd= {line.split(' ')[0]:float(line.split(' ')[3]) \n",
    "              for line in zhunt.split('\\n')}\n",
    "        ZHUNT_SAd= {line.split(' ')[0]:float(line.split(' ')[4]) \n",
    "              for line in zhunt.split('\\n')}\n",
    "        self.configs = {\"ZHUNT_AS\":ZHUNT_AS,\n",
    "                       \"ZHUNT_SA\":ZHUNT_SA,\n",
    "                       \"ZHUNT_ASd\":ZHUNT_ASd,\n",
    "                       \"ZHUNT_SAd\":ZHUNT_SAd}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.intervals)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        interval = self.intervals[index]\n",
    "        chrom = interval[0]\n",
    "        begin = int(interval[1])\n",
    "        end = int(interval[2])\n",
    "        \n",
    "        ll = list(self.dna_source[chrom][begin:end].upper())\n",
    "        dna_OHE = self.le.transform(ll)\n",
    "        \n",
    "        zhunts = []\n",
    "        for key in self.configs:\n",
    "            vec = np.array(ll)\n",
    "            vec = np.vectorize(lambda x:self.configs[key].get(x, 0))(\n",
    "                                    np.char.add(vec[1:], vec[:-1]))\n",
    "            zhunts.append(np.concatenate([vec, [0]]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_matr = []\n",
    "        for feature in self.features:\n",
    "            source = self.features_source[feature]\n",
    "            feature_matr.append(source[chrom][begin:end])\n",
    "            \n",
    "        if len(feature_matr) > 0:\n",
    "            X = np.hstack((dna_OHE, \n",
    "                           np.array(zhunts).T,\n",
    "                           np.array(feature_matr).T/1000)).astype(np.float32)\n",
    "        else:\n",
    "            X = dna_OHE.astype(np.float32)\n",
    "        y = self.labels_source[interval[0]][interval[1]: interval[2]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        return (X, y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31919/31919 [00:09<00:00, 3317.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "29549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "width = 5000\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "ints_in = []\n",
    "ints_out = []\n",
    "\n",
    "\n",
    "for chrm in chroms:\n",
    "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
    "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
    "        N_count = sum([bp == \"N\" for bp in DNA[chrm][interval[0]:interval[1]]])\n",
    "        bl_count = black_list[chrm][interval[0]:interval[1]].sum()\n",
    "        if N_count > width / 2 or bl_count > 0:\n",
    "            continue\n",
    "        else:\n",
    "            if ZDNA[chrm][interval[0]: interval[1]].any():\n",
    "                ints_in.append([chrm, interval[0], interval[1]])\n",
    "            else:\n",
    "                ints_out.append([chrm, interval[0], interval[1]])\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "print(len(ints_in))\n",
    "print(len(ints_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n",
      "258\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "ints_in = np.array(ints_in)\n",
    "ints_out = np.array(ints_out)[np.random.choice(range(len(ints_out)), \n",
    "                                                          size=len(ints_in) * 3, replace=False)]\n",
    "\n",
    "print(len(ints_in))\n",
    "print(len(ints_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dna_lens = {i:len(DNA[i])for i in DNA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ints_out = [i for i in ints_out if (int(i[1]) < dna_lens[i[0]]) and (int(i[2]) < dna_lens[i[0]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "equalized = np.vstack((ints_in, ints_out))\n",
    "equalized = [[inter[0], int(inter[1]), int(inter[2])] for inter in equalized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "divisions = list(StratifiedKFold(5, shuffle=True, \n",
    "                                 random_state=42).split(equalized, [f\"{int(i < len(ints_in))}_{elem[0]}\"\n",
    "                                         for i, elem \n",
    "                                         in enumerate(equalized)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inds, test_inds = divisions[MODEL_NUMBER]\n",
    "\n",
    "\n",
    "train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]\n",
    "\n",
    "train_dataset = Dataset(chroms, feature_names, \n",
    "                       DNA, DNA_features, \n",
    "                       ZDNA, train_intervals)\n",
    "\n",
    "test_dataset = Dataset(chroms, feature_names, \n",
    "                       DNA, DNA_features, \n",
    "                       ZDNA, test_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class DeepZ(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(881, 100, 1, bidirectional=True)\n",
    "        self.seq = nn.Sequential(\n",
    "                nn.Linear(2 * 100, 100),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Dropout(0.25),\n",
    "                nn.Linear(100, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, (h_n, c_n) = self.rnn(x)\n",
    "        x = self.seq(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'batch_size':30,\n",
    "          'num_workers':5,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = data.DataLoader(train_dataset, **params)\n",
    "loader_test = data.DataLoader(test_dataset, **params)\n",
    "\n",
    "\n",
    "train_log, train_acc_log, train_auc_log, train_f1_log = [], [], [], []\n",
    "val_log,   val_acc_log,   val_auc_log, val_f1_log   = [], [], [], []\n",
    "# best_auc = 0\n",
    "# log = open(f\"../models/{ASSEMBLY}/log_{MODEL_NUMBER}\", 'w')\n",
    "# log.write(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\") + \"\\n\")\n",
    "# log.close()\n",
    "    \n",
    "def loss_func(output, y_batch):\n",
    "    return torch.nn.NLLLoss()(torch.transpose(output, 2, 1), y_batch)\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    loss_log, acc_log, roc_auc_log, f1_log = [], [], [], []\n",
    "    model.train()\n",
    "    for X_batch, y_batch in tqdm(loader_train):\n",
    "        X_batch, y_batch = X_batch.cuda(), y_batch.cuda().long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        pred = torch.argmax(output, dim=2)\n",
    "        y_pred = nn.Softmax(dim=1)(output)[:, :,1].detach().cpu().numpy().flatten()\n",
    "        if np.std(y_batch.cpu().numpy().flatten()) == 0:\n",
    "            roc_auc = 0\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_batch.cpu().numpy().flatten(),\n",
    "                                    nn.Softmax(dim=1)(output)[:, :,1].detach().cpu().numpy().flatten())\n",
    "        f1_log.append(f1_score(y_batch.cpu().numpy().flatten(),\n",
    "                         pred.cpu().numpy().flatten()))\n",
    "        roc_auc_log.append(roc_auc)\n",
    "        acc = torch.mean((pred == y_batch).float())\n",
    "        acc_log.append(acc.cpu().numpy())\n",
    "        loss = loss_func(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log, acc_log, roc_auc_log, f1_log\n",
    "\n",
    "def test(model):\n",
    "    loss_log, acc_log, roc_auc_log, f1_log = [], [], [], []\n",
    "    model.eval()\n",
    "    means = []\n",
    "    for X_batch, y_batch in tqdm(loader_test):\n",
    "        X_batch, y_batch = X_batch.cuda(), y_batch.cuda().long()\n",
    "        output = model(X_batch)\n",
    "        means.append(y_batch.sum().cpu() / (1.0 * y_batch.shape[0]))\n",
    "        pred = torch.argmax(output, dim=2)\n",
    "        if np.std(y_batch.cpu().numpy().flatten()) == 0:\n",
    "            roc_auc = 0\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_batch.cpu().numpy().flatten(),\n",
    "                                    nn.Softmax(dim=1)(output)[:, :,1].detach().cpu().numpy().flatten())\n",
    "        f1_log.append(f1_score(y_batch.cpu().numpy().flatten(),\n",
    "                                  pred.cpu().numpy().flatten()))\n",
    "        roc_auc_log.append(roc_auc)\n",
    "        acc = torch.mean((pred == y_batch).float())\n",
    "        acc_log.append(acc.cpu().numpy())\n",
    "        loss = loss_func(output, y_batch)\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log, acc_log, roc_auc_log, f1_log\n",
    "\n",
    "def plot_history(train_history, valid_history, title, BatchSize, epoch_to_show=20):\n",
    "    plt.figure(figsize=(epoch_to_show, 4))\n",
    "    plt.title(title)    \n",
    "    \n",
    "    epoch_num = len(valid_history)\n",
    "    train_history = np.array([None] * (BatchSize * epoch_to_show) + train_history)\n",
    "    valid_history = np.array([None] * epoch_to_show + valid_history)\n",
    "    \n",
    "    plt.plot(np.linspace(epoch_num-epoch_to_show+1, epoch_num+1, (epoch_to_show+1)*BatchSize), \n",
    "             train_history[-(epoch_to_show+1)*BatchSize:], c='red', label='train')\n",
    "    plt.plot(np.linspace(epoch_num-epoch_to_show+1, epoch_num+1, epoch_to_show+1),\n",
    "                valid_history[-epoch_to_show-1:], c='green', label='test')\n",
    "    \n",
    "    plt.ylim((0, 1))\n",
    "    plt.yticks(np.linspace(0, 1, 11))\n",
    "    plt.xticks(np.arange(epoch_num-epoch_to_show+1, epoch_num+2), \n",
    "              np.arange(epoch_num-epoch_to_show, epoch_num+1).astype(int))\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs):\n",
    "    global best_auc\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {} of {}\".format(epoch + 1, n_epochs))\n",
    "        train_loss, train_acc, train_auc, train_f1 = train_epoch(model, opt)\n",
    "        val_loss, val_acc, val_auc, val_f1 = test(model)\n",
    "        \n",
    "        BatchSize = len(train_loss)\n",
    "        \n",
    "        train_log.extend(train_loss)\n",
    "        train_acc_log.extend(train_acc)\n",
    "        train_auc_log.extend(train_auc)\n",
    "        train_f1_log.extend(train_f1)\n",
    "\n",
    "        val_log.append(np.mean(val_loss))\n",
    "        val_acc_log.append(np.mean(val_acc))\n",
    "        val_auc_log.append(np.mean(val_auc))\n",
    "        val_f1_log.append(np.mean(val_f1))\n",
    "        \n",
    "        if (epoch % 1) == 0:\n",
    "            clear_output()\n",
    "            plot_history(train_log,     val_log,     'Loss',     BatchSize)    \n",
    "            plot_history(train_acc_log, val_acc_log, 'Accuracy', BatchSize)\n",
    "            plot_history(train_auc_log, val_auc_log, 'Auc',      BatchSize)\n",
    "            plot_history(train_f1_log, val_f1_log,   'F1',       BatchSize)\n",
    "            print(\"Epoch {} AUC = {:.2%}\".format(epoch+1, val_auc_log[-1]))\n",
    "            print(\"Epoch {} accuracy = {:.2%}\".format(epoch+1, val_acc_log[-1]))\n",
    "            \n",
    "#             if val_auc_log[-1] > best_auc:\n",
    "#                 best_auc = val_auc_log[-1]\n",
    "#                 torch.save(model.state_dict(), f\"../models/{ASSEMBLY}/model_{MODEL_NUMBER}\")\n",
    "#                 log = open(f\"../models/{ASSEMBLY}/log_{MODEL_NUMBER}\", 'a')\n",
    "#                 log.write(str(best_auc) + \"\\n\")\n",
    "#                 log.close()\n",
    "            \n",
    "    print(\"Final AUC: {:.2}\".format(1 - val_auc_log[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepZ()\n",
    "model = model.cuda()\n",
    "print(\"Total number of trainable parameters:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = torch.optim.RMSprop(model.parameters(), lr=10**-3, weight_decay=10**-3)\n",
    "train(model, opt, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
