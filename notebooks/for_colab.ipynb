{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nature.com/articles/s41598-020-76203-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ie_V2E5Wbl5S"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/Nazar1997/bioinformatics_school --recursive\n",
    "pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "POgsZhMsbyD9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import os\n",
    "from bioinformatics_school.notebooks.Sparse_vector.sparse_vector import SparseVector\n",
    "from joblib import load, dump, Parallel, delayed\n",
    "\n",
    "taget_antigen = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "chroms = [f'chr3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "37K9tpUDpzCr"
   },
   "source": [
    "# DNA download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atFg4MYtb3du"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir bioinformatics_school/data/mm9_dna\n",
    "mkdir bioinformatics_school/data/mm9_dna/raw\n",
    "mkdir bioinformatics_school/data/mm9_dna/sparse\n",
    "cd bioinformatics_school/data/mm9_dna/raw\n",
    "wget http://hgdownload.cse.ucsc.edu/goldenPath/mm9/chromosomes/chr3.fa.gz\n",
    "gzip -d chr3.fa.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hE4pue3jcCxx",
    "outputId": "579ae9a3-cd67-4a79-dacb-48e92ca968cb"
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "for record in tqdm(SeqIO.parse(\"bioinformatics_school/data/mm9_dna/raw/chr3.fa\", \"fasta\")):\n",
    "    if record.id in chroms:\n",
    "        dump(str(record.seq.upper()), f\"bioinformatics_school/data/mm9_dna/sparse/{record.id}.pkl\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bKwMFZByqZxV",
    "outputId": "e8d7eef7-06fc-4ba5-b391-337ebfe28c6b"
   },
   "outputs": [],
   "source": [
    "dna = {chrom:load(f'bioinformatics_school/data/mm9_dna/sparse/{chrom}.pkl') for chrom in tqdm(chroms)}\n",
    "lens_of_chroms = {chrom: len(dna[chrom]) for chrom in dna}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tbOATRkmp2-K"
   },
   "source": [
    "# Target prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uZLwkEw1cSLQ"
   },
   "outputs": [],
   "source": [
    "def processor(file):\n",
    "    loc_dd = {chrm:SparseVector(lens_of_chroms[chrm]) for chrm in chroms}\n",
    "    df = pd.read_csv(f'bioinformatics_school/data/mm9_zdna/raw/{file}', sep='\\t', header=None)\n",
    "    for chrom, sub_df in tqdm(df.groupby(0)):\n",
    "        if chrom not in chroms:\n",
    "            continue\n",
    "        vec = np.zeros(lens_of_chroms[chrom])\n",
    "        for inter in sub_df.values:\n",
    "            vec[inter[1]:inter[2]+1] = np.maximum(vec[inter[1]:inter[2]+1], 1)\n",
    "        loc_dd[chrom] = SparseVector(vec)\n",
    "\n",
    "    dump(loc_dd, f'bioinformatics_school/data/mm9_zdna/sparse/{file[:-4]}.pkl', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZmFIAJtrqIjO",
    "outputId": "6324ef29-0102-4e5d-eed8-4db5d57636ea"
   },
   "outputs": [],
   "source": [
    "for file in os.listdir('bioinformatics_school/data/mm9_zdna/raw/'):\n",
    "    if file.startswith(\"zdna_\"):\n",
    "        processor(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6UAUZ6_WqNfe",
    "outputId": "eae0976b-ce04-47f9-bf0d-28038c9b3a90"
   },
   "outputs": [],
   "source": [
    "loc_dd = {chrm:SparseVector(lens_of_chroms[chrm]) for chrm in chroms}\n",
    "df = pd.read_csv('bioinformatics_school/data/mm9_zdna/raw/blacklist_mm9.bed', sep='\\t', header=None, names=range(3), index_col=False)\n",
    "for chrom, sub_df in tqdm(df.groupby(0)):\n",
    "    if chrom not in chroms:\n",
    "        continue\n",
    "    vec = np.zeros(lens_of_chroms[chrom])\n",
    "    for inter in sub_df.values:\n",
    "        vec[inter[1]:inter[2]+1] = np.maximum(vec[inter[1]:inter[2]+1], 1)\n",
    "    loc_dd[chrom] = SparseVector(vec)\n",
    "dump(loc_dd, f'bioinformatics_school/data/mm9_zdna/sparse/blacklist_mm9.pkl', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyhL7UAjqPSc"
   },
   "source": [
    "# Model trainig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JY02UJiDaGkW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import trange\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from joblib import Parallel, delayed, dump, load\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Choose visible device\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "# Select model number. From 0 to 4, as much as number of folds\n",
    "MODEL_NUMBER = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuW2uHalbuUc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_ci1WoKaGkY"
   },
   "outputs": [],
   "source": [
    "chroms = [f'chr{i}' for i in list(range(1, 20)) + ['X', 'Y']]\n",
    "all_features = sorted([i[:-4] for i in os.listdir('bioinformatics_school/data/mm9_features/sparse/') if i.endswith('.pkl')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fg8x4C3daGkZ"
   },
   "outputs": [],
   "source": [
    "chroms = ['chr3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Ajo2ZYzaGkZ"
   },
   "outputs": [],
   "source": [
    "groups = ['DNase-seq', 'Histone', 'RNA polymerase', 'TFs and others']\n",
    "groups = ['Histone', 'RNA polymerase', 'TFs and others']\n",
    "feature_names = [i for i in all_features if (i.split('_')[0] in groups)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NQObfTIQeFVB"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./bioinformatics_school/notebooks/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qQmvRoocqbs"
   },
   "outputs": [],
   "source": [
    "import Sparse_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cHSHcx5WaGkZ"
   },
   "outputs": [],
   "source": [
    "ZDNA = load(f'bioinformatics_school/data/mm9_zdna/sparse/zdna_mm9.pkl')\n",
    "black_list = load(f'bioinformatics_school/data/mm9_zdna/sparse/blacklist_mm9.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IXU9Ho6VaGka",
    "outputId": "56a02767-bb66-4330-d858-346c9849d0fc"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# load all the data\n",
    "DNA = {chrom:load(f'bioinformatics_school/data/mm9_dna/sparse/{chrom}.pkl') for chrom in tqdm(chroms)}\n",
    "\n",
    "DNA_features = {feture: load(f'bioinformatics_school/data/mm9_features/sparse/{feture}.pkl')\n",
    "                for feture in tqdm(feature_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXGDNpITaGkb",
    "outputId": "7f997e0a-d76f-4153-86d9-8a09a1fc8097"
   },
   "outputs": [],
   "source": [
    "for feature in tqdm(DNA_features):\n",
    "    if set(DNA_features[feature].keys()) != set(chroms):\n",
    "        for chrom in chroms:\n",
    "            if chrom not in DNA_features[feature]:\n",
    "                DNA_features[feature][chrom] = SparseVector(len(DNA[chrom]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5OlXZ22aGkb"
   },
   "source": [
    "# DL code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6frFSRw1aGkc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils import data\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4zWSPnwcaGkc"
   },
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, chroms, features, \n",
    "                 dna_source, features_source, \n",
    "                 labels_source, intervals):\n",
    "        self.chroms = chroms\n",
    "        self.features = features\n",
    "        self.dna_source = dna_source\n",
    "        self.features_source = features_source\n",
    "        self.labels_source = labels_source\n",
    "        self.intervals = intervals\n",
    "        self.le = LabelBinarizer().fit(np.array([[\"A\"], [\"C\"], [\"T\"], [\"G\"]]))\n",
    "        zhunt = \"\"\"CG 0.7 4.0 4.0 4.0\n",
    "GC 4.0 0.7 4.0 4.0\n",
    "CA 1.3 4.6 4.5 4.5\n",
    "AC 4.6 1.3 4.5 4.5\n",
    "TG 1.3 4.6 4.5 4.5\n",
    "GT 4.6 1.3 4.5 4.5\n",
    "TA 2.5 5.9 5.6 5.6\n",
    "AT 5.9 2.5 5.6 5.6\n",
    "CC 2.4 2.4 4.0 4.0\n",
    "GG 2.4 2.4 4.0 4.0\n",
    "CT 3.4 3.4 6.3 6.3\n",
    "TC 3.4 3.4 6.3 6.3\n",
    "GA 3.4 3.4 6.3 6.3\n",
    "AG 3.4 3.4 6.3 6.3\n",
    "AA 3.9 3.9 7.4 7.4\n",
    "TT 3.9 3.9 7.4 7.4\"\"\"\n",
    "        ZHUNT_AS = {line.split(' ')[0]:float(line.split(' ')[1]) \n",
    "              for line in zhunt.split('\\n')}\n",
    "        ZHUNT_SA = {line.split(' ')[0]:float(line.split(' ')[2]) \n",
    "              for line in zhunt.split('\\n')}\n",
    "        ZHUNT_ASd= {line.split(' ')[0]:float(line.split(' ')[3]) \n",
    "              for line in zhunt.split('\\n')}\n",
    "        ZHUNT_SAd= {line.split(' ')[0]:float(line.split(' ')[4]) \n",
    "              for line in zhunt.split('\\n')}\n",
    "        self.configs = {\"ZHUNT_AS\":ZHUNT_AS,\n",
    "                       \"ZHUNT_SA\":ZHUNT_SA,\n",
    "                       \"ZHUNT_ASd\":ZHUNT_ASd,\n",
    "                       \"ZHUNT_SAd\":ZHUNT_SAd}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.intervals)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        interval = self.intervals[index]\n",
    "        chrom = interval[0]\n",
    "        begin = int(interval[1])\n",
    "        end = int(interval[2])\n",
    "        \n",
    "        ll = list(self.dna_source[chrom][begin:end].upper())\n",
    "        dna_OHE = self.le.transform(ll)\n",
    "        \n",
    "        zhunts = []\n",
    "        for key in self.configs:\n",
    "            vec = np.array(ll)\n",
    "            vec = np.vectorize(lambda x:self.configs[key].get(x, 0))(\n",
    "                                    np.char.add(vec[1:], vec[:-1]))\n",
    "            zhunts.append(np.concatenate([vec, [0]]))\n",
    "        \n",
    "        \n",
    "        \n",
    "        feature_matr = []\n",
    "        for feature in self.features:\n",
    "            source = self.features_source[feature]\n",
    "            feature_matr.append(source[chrom][begin:end])\n",
    "            \n",
    "        if len(feature_matr) > 0:\n",
    "            X = np.hstack((dna_OHE, \n",
    "                           np.array(zhunts).T,\n",
    "                           np.array(feature_matr).T/1000)).astype(np.float32)\n",
    "        else:\n",
    "            X = dna_OHE.astype(np.float32)\n",
    "        y = self.labels_source[interval[0]][interval[1]: interval[2]]\n",
    "        \n",
    "        \n",
    "        \n",
    "        return (X, y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BCH9gfgKaGkd",
    "outputId": "a7ee6c32-ddfc-4872-d6f8-9669352270ca"
   },
   "outputs": [],
   "source": [
    "width = 5000\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "ints_in = []\n",
    "ints_out = []\n",
    "\n",
    "\n",
    "for chrm in chroms:\n",
    "    for st in trange(0, ZDNA[chrm].shape - width, width):\n",
    "        interval = [st, min(st + width, ZDNA[chrm].shape)]\n",
    "        N_count = sum([bp == \"N\" for bp in DNA[chrm][interval[0]:interval[1]]])\n",
    "        bl_count = black_list[chrm][interval[0]:interval[1]].sum()\n",
    "        if N_count > width / 2 or bl_count > 0:\n",
    "            continue\n",
    "        else:\n",
    "            if ZDNA[chrm][interval[0]: interval[1]].any():\n",
    "                ints_in.append([chrm, interval[0], interval[1]])\n",
    "            else:\n",
    "                ints_out.append([chrm, interval[0], interval[1]])\n",
    "\n",
    "\n",
    "                \n",
    "                \n",
    "print(len(ints_in))\n",
    "print(len(ints_out))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Duq6Yr2LaGkd",
    "outputId": "6d3e0572-5dfe-4b68-937d-565de8210707"
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "ints_in = np.array(ints_in)\n",
    "ints_out = np.array(ints_out)[np.random.choice(range(len(ints_out)), \n",
    "                                                          size=len(ints_in) * 3, replace=False)]\n",
    "\n",
    "print(len(ints_in))\n",
    "print(len(ints_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g2vK6UpNaGkd"
   },
   "outputs": [],
   "source": [
    "dna_lens = {i:len(DNA[i])for i in DNA}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "px4rSyHPaGke"
   },
   "outputs": [],
   "source": [
    "ints_out = [i for i in ints_out if (int(i[1]) < dna_lens[i[0]]) and (int(i[2]) < dna_lens[i[0]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "87UE_yMhaGke"
   },
   "outputs": [],
   "source": [
    "equalized = np.vstack((ints_in, ints_out))\n",
    "equalized = [[inter[0], int(inter[1]), int(inter[2])] for inter in equalized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QlAvAVxraGke"
   },
   "outputs": [],
   "source": [
    "divisions = list(StratifiedKFold(5, shuffle=True, \n",
    "                                 random_state=42).split(equalized, [f\"{int(i < len(ints_in))}_{elem[0]}\"\n",
    "                                         for i, elem \n",
    "                                         in enumerate(equalized)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BhJ6WNUSaGke"
   },
   "outputs": [],
   "source": [
    "train_inds, test_inds = divisions[MODEL_NUMBER]\n",
    "\n",
    "\n",
    "train_intervals, test_intervals = [equalized[i] for i in train_inds], [equalized[i] for i in test_inds]\n",
    "\n",
    "train_dataset = Dataset(chroms, feature_names, \n",
    "                       DNA, DNA_features, \n",
    "                       ZDNA, train_intervals)\n",
    "\n",
    "test_dataset = Dataset(chroms, feature_names, \n",
    "                       DNA, DNA_features, \n",
    "                       ZDNA, test_intervals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8v4AkI1UaGkf"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class DeepZ(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.LSTM(879, 100, 1, bidirectional=True)\n",
    "        self.seq = nn.Sequential(\n",
    "                nn.Linear(2 * 100, 100),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Dropout(0.25),\n",
    "                nn.Linear(100, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x, (h_n, c_n) = self.rnn(x)\n",
    "        x = self.seq(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fLFSPkW2aGkf"
   },
   "outputs": [],
   "source": [
    "params = {'batch_size':30,\n",
    "          'num_workers':5,\n",
    "          'shuffle':True}\n",
    "\n",
    "loader_train = data.DataLoader(train_dataset, **params)\n",
    "loader_test = data.DataLoader(test_dataset, **params)\n",
    "\n",
    "\n",
    "train_log, train_acc_log, train_auc_log, train_f1_log = [], [], [], []\n",
    "val_log,   val_acc_log,   val_auc_log, val_f1_log   = [], [], [], []\n",
    "# best_auc = 0\n",
    "# log = open(f\"../models/{ASSEMBLY}/log_{MODEL_NUMBER}\", 'w')\n",
    "# log.write(datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\") + \"\\n\")\n",
    "# log.close()\n",
    "    \n",
    "def loss_func(output, y_batch):\n",
    "    return torch.nn.NLLLoss()(torch.transpose(output, 2, 1), y_batch)\n",
    "\n",
    "def train_epoch(model, optimizer):\n",
    "    loss_log, acc_log, roc_auc_log, f1_log = [], [], [], []\n",
    "    model.train()\n",
    "    for X_batch, y_batch in tqdm(loader_train):\n",
    "        X_batch, y_batch = X_batch.cuda(), y_batch.cuda().long()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        pred = torch.argmax(output, dim=2)\n",
    "        y_pred = nn.Softmax(dim=1)(output)[:, :,1].detach().cpu().numpy().flatten()\n",
    "        if np.std(y_batch.cpu().numpy().flatten()) == 0:\n",
    "            roc_auc = 0\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_batch.cpu().numpy().flatten(),\n",
    "                                    nn.Softmax(dim=1)(output)[:, :,1].detach().cpu().numpy().flatten())\n",
    "        f1_log.append(f1_score(y_batch.cpu().numpy().flatten(),\n",
    "                         pred.cpu().numpy().flatten()))\n",
    "        roc_auc_log.append(roc_auc)\n",
    "        acc = torch.mean((pred == y_batch).float())\n",
    "        acc_log.append(acc.cpu().numpy())\n",
    "        loss = loss_func(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log, acc_log, roc_auc_log, f1_log\n",
    "\n",
    "def test(model):\n",
    "    loss_log, acc_log, roc_auc_log, f1_log = [], [], [], []\n",
    "    model.eval()\n",
    "    means = []\n",
    "    for X_batch, y_batch in tqdm(loader_test):\n",
    "        X_batch, y_batch = X_batch.cuda(), y_batch.cuda().long()\n",
    "        output = model(X_batch)\n",
    "        means.append(y_batch.sum().cpu() / (1.0 * y_batch.shape[0]))\n",
    "        pred = torch.argmax(output, dim=2)\n",
    "        if np.std(y_batch.cpu().numpy().flatten()) == 0:\n",
    "            roc_auc = 0\n",
    "        else:\n",
    "            roc_auc = roc_auc_score(y_batch.cpu().numpy().flatten(),\n",
    "                                    nn.Softmax(dim=1)(output)[:, :,1].detach().cpu().numpy().flatten())\n",
    "        f1_log.append(f1_score(y_batch.cpu().numpy().flatten(),\n",
    "                                  pred.cpu().numpy().flatten()))\n",
    "        roc_auc_log.append(roc_auc)\n",
    "        acc = torch.mean((pred == y_batch).float())\n",
    "        acc_log.append(acc.cpu().numpy())\n",
    "        loss = loss_func(output, y_batch)\n",
    "        loss = loss.item()\n",
    "        loss_log.append(loss)\n",
    "    return loss_log, acc_log, roc_auc_log, f1_log\n",
    "\n",
    "def plot_history(train_history, valid_history, title, BatchSize, epoch_to_show=20):\n",
    "    plt.figure(figsize=(epoch_to_show, 4))\n",
    "    plt.title(title)    \n",
    "    \n",
    "    epoch_num = len(valid_history)\n",
    "    train_history = np.array([None] * (BatchSize * epoch_to_show) + train_history)\n",
    "    valid_history = np.array([None] * epoch_to_show + valid_history)\n",
    "    \n",
    "    plt.plot(np.linspace(epoch_num-epoch_to_show+1, epoch_num+1, (epoch_to_show+1)*BatchSize), \n",
    "             train_history[-(epoch_to_show+1)*BatchSize:], c='red', label='train')\n",
    "    plt.plot(np.linspace(epoch_num-epoch_to_show+1, epoch_num+1, epoch_to_show+1),\n",
    "                valid_history[-epoch_to_show-1:], c='green', label='test')\n",
    "    \n",
    "    plt.ylim((0, 1))\n",
    "    plt.yticks(np.linspace(0, 1, 11))\n",
    "    plt.xticks(np.arange(epoch_num-epoch_to_show+1, epoch_num+2), \n",
    "              np.arange(epoch_num-epoch_to_show, epoch_num+1).astype(int))\n",
    "    plt.xlabel('train steps')\n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, opt, n_epochs):\n",
    "    global best_auc\n",
    "    for epoch in range(n_epochs):\n",
    "        print(\"Epoch {} of {}\".format(epoch + 1, n_epochs))\n",
    "        train_loss, train_acc, train_auc, train_f1 = train_epoch(model, opt)\n",
    "        val_loss, val_acc, val_auc, val_f1 = test(model)\n",
    "        \n",
    "        BatchSize = len(train_loss)\n",
    "        \n",
    "        train_log.extend(train_loss)\n",
    "        train_acc_log.extend(train_acc)\n",
    "        train_auc_log.extend(train_auc)\n",
    "        train_f1_log.extend(train_f1)\n",
    "\n",
    "        val_log.append(np.mean(val_loss))\n",
    "        val_acc_log.append(np.mean(val_acc))\n",
    "        val_auc_log.append(np.mean(val_auc))\n",
    "        val_f1_log.append(np.mean(val_f1))\n",
    "        \n",
    "        if (epoch % 1) == 0:\n",
    "            clear_output()\n",
    "            plot_history(train_log,     val_log,     'Loss',     BatchSize)    \n",
    "            plot_history(train_acc_log, val_acc_log, 'Accuracy', BatchSize)\n",
    "            plot_history(train_auc_log, val_auc_log, 'Auc',      BatchSize)\n",
    "            plot_history(train_f1_log, val_f1_log,   'F1',       BatchSize)\n",
    "            print(\"Epoch {} AUC = {:.2%}\".format(epoch+1, val_auc_log[-1]))\n",
    "            print(\"Epoch {} accuracy = {:.2%}\".format(epoch+1, val_acc_log[-1]))\n",
    "            \n",
    "#             if val_auc_log[-1] > best_auc:\n",
    "#                 best_auc = val_auc_log[-1]\n",
    "#                 torch.save(model.state_dict(), f\"../models/{ASSEMBLY}/model_{MODEL_NUMBER}\")\n",
    "#                 log = open(f\"../models/{ASSEMBLY}/log_{MODEL_NUMBER}\", 'a')\n",
    "#                 log.write(str(best_auc) + \"\\n\")\n",
    "#                 log.close()\n",
    "            \n",
    "    print(\"Final AUC: {:.2}\".format(1 - val_auc_log[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_lTXDf9jaGkh"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZPAQz-MJaGki"
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    return sum([np.prod(p.size()) for p in model_parameters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gCwOTETyaGki",
    "outputId": "df069331-95fd-4e8a-8791-6b92cee2385e"
   },
   "outputs": [],
   "source": [
    "model = DeepZ()\n",
    "model = model.cuda()\n",
    "print(\"Total number of trainable parameters:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jeqUm_dBaGki"
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.RMSprop(model.parameters(), lr=10**-3, weight_decay=10**-3)\n",
    "train(model, opt, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGjLtkfsaGkj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LUuYp_AwaGkj"
   },
   "outputs": [],
   "source": [
    "class linear_DeepZ(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "                nn.Linear(879, 2)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.seq(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qeOs3r0caGkj",
    "outputId": "181e0052-1349-45c9-c62a-448af2de7c47"
   },
   "outputs": [],
   "source": [
    "model = linear_DeepZ()\n",
    "model = model.cuda()\n",
    "print(\"Total number of trainable parameters:\", count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BB-5F3YZaGkj"
   },
   "outputs": [],
   "source": [
    "opt = torch.optim.RMSprop(model.parameters(), lr=10**-3, weight_decay=10**-3)\n",
    "train(model, opt, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYM5I1FBaGkj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rzSOGFOBaGkj"
   },
   "outputs": [],
   "source": [
    "weights = model.seq[0].cpu().weight.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1swaMAJaGkj"
   },
   "outputs": [],
   "source": [
    "coef = weights[0] - weights[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qHXFONa8oO2z"
   },
   "outputs": [],
   "source": [
    "feus = [\"DNA_A\", \"DNA_C\", \"DNA_T\", \"DNA_G\"] + [\"ZHUNT_AS\", \"ZHUNT_SA\", \"ZHUNT_ASd\",\"ZHUNT_SAd\"] + \\\n",
    "       train_dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZWpjgrGsaGkj"
   },
   "outputs": [],
   "source": [
    "smth = sorted([(j, i) for i,j in zip(feus, coef)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "2DIEOgZHaGkj",
    "outputId": "55e3f2f8-94aa-4f4f-9783-9aee6b1ced59"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 10))\n",
    "plt.barh(np.arange(41), [i[0] for i in smth[:20]] + [0] + [i[0] for i in smth[-20:]])\n",
    "plt.grid()\n",
    "plt.title(\"Feature importance\")\n",
    "plt.yticks(np.arange(41), \n",
    "           [i.split(\"_\")[1] \n",
    "            for i in [i[1] for i in smth[:20]] + [\"_\"] + [i[1] for i in smth[-20:]]], \n",
    "#            rotation='vertical'\n",
    "          )\n",
    "# plt.ylim(-12, 12)\n",
    "# plt.savefig('feature_importance_Z22.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hdtXHnNjaGkj"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMIJjEUVogeu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lJehGLDaoghV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhkXXReHogjv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5M8-kxDQogmY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DL_model_trainig.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
